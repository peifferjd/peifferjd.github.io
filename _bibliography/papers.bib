---
---

@string{aps = {American Physical Society,}}


@article{bryson_enhanced_2023,
	title = {Enhanced selectivity of transcutaneous spinal cord stimulation by multielectrode configuration},
	volume = {20},
	issn = {1741-2560, 1741-2552},
	url = {https://iopscience.iop.org/article/10.1088/1741-2552/ace552},
	doi = {10.1088/1741-2552/ace552},
	abstract = {Abstract
            
              Objective.
              Transcutaneous spinal cord stimulation ({tSCS}) has been gaining momentum as a non-invasive rehabilitation approach to restore movement to paralyzed muscles after spinal cord injury ({SCI}). However, its low selectivity limits the types of movements that can be enabled and, thus, its potential applications in rehabilitation.
              Approach.
              In this cross-over study design, we investigated whether muscle recruitment selectivity of individual muscles could be enhanced by multielectrode configurations of {tSCS} in 16 neurologically intact individuals. We hypothesized that due to the segmental innervation of lower limb muscles, we could identify muscle-specific optimal stimulation locations that would enable improved recruitment selectivity over conventional {tSCS}. We elicited leg muscle responses by delivering biphasic pulses of electrical stimulation to the lumbosacral enlargement using conventional and multielectrode {tSCS}.
              Results.
              Analysis of recruitment curve responses confirmed that multielectrode configurations could improve the rostrocaudal and lateral selectivity of {tSCS}. To investigate whether motor responses elicited by spatially selective {tSCS} were mediated by posterior root-muscle reflexes, each stimulation event was a paired pulse with a conditioning-test interval of 33.3 ms. Muscle responses to the second stimulation pulse were significantly suppressed, a characteristic of post-activation depression suggesting that spatially selective {tSCS} recruits proprioceptive fibers that reflexively activate muscle-specific motor neurons in the spinal cord. Moreover, the combination of leg muscle recruitment probability and segmental innervation maps revealed a stereotypical spinal activation map in congruence with each electrode’s position.
              Significance
              . Improvements in muscle recruitment selectivity could be essential for the effective translation into stimulation protocols that selectively enhance single-joint movements in neurorehabilitation.},
	pages = {046015},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Bryson, Noah and Lombardi, Lorenzo and Hawthorn, Rachel and Fei, Jie and Keesey, Rodolfo and Peiffer, J D and Seáñez, Ismael},
	urldate = {2023-08-03},
	date = {2023-08-01},
	langid = {english},
}

@inproceedings{cotton_optimizing_2023,
	location = {Singapore, Singapore},
	title = {Optimizing Trajectories and Inverse Kinematics for Biomechanical Analysis of Markerless Motion Capture Data},
	isbn = {979-8-3503-4275-8},
	url = {https://ieeexplore.ieee.org/document/10304683/},
	doi = {10.1109/ICORR58425.2023.10304683},
	abstract = {Markerless motion capture using computer vision and human pose estimation ({HPE}) has the potential to expand access to precise movement analysis. This could greatly benefit rehabilitation by enabling more accurate tracking of outcomes and providing more sensitive tools for research. There are numerous steps between obtaining videos to extracting accurate biomechanical results and limited research to guide many critical design decisions in these pipelines. In this work, we analyze several of these steps including the algorithm used to detect keypoints and the keypoint set, the approach to reconstructing trajectories for biomechanical inverse kinematics and optimizing the {IK} process. Several features we find important are: 1) using a recent algorithm trained on many datasets that produces a dense set of biomechanically-motivated keypoints, 2) using an implicit representation to reconstruct smooth, anatomically constrained marker trajectories for {IK}, 3) iteratively optimizing the biomechanical model to match the dense markers, 4) appropriate regularization of the {IK} process. Our pipeline makes it easy to obtain accurate biomechanical estimates of movement in a rehabilitation hospital.},
	eventtitle = {2023 International Conference on Rehabilitation Robotics ({ICORR})},
	pages = {1--6},
	booktitle = {2023 International Conference on Rehabilitation Robotics ({ICORR})},
	publisher = {{IEEE}},
	author = {Cotton, R. James and {DeLillo}, Allison and Cimorelli, Anthony and Shah, Kunal and Peiffer, J.D. and Anarwala, Shawana and Abdou, Kayan and Karakostas, Tasos},
	urldate = {2023-11-17},
	date = {2023-09-24},
	langid = {english},
}


@article{peiffer_hyperpolarized_2024,
	title = {Hyperpolarized 129Xe {MRI}, 99mTc scintigraphy, and {SPECT} in lung ventilation imaging: a quantitative comparison},
	volume = {31},
	issn = {1076-6332},
	url = {https://www.sciencedirect.com/science/article/pii/S1076633223005913},
	doi = {10.1016/j.acra.2023.10.038},
	shorttitle = {Hyperpolarized 129Xe {MRI}, 99mTc scintigraphy, and {SPECT} in lung ventilation imaging},
	abstract = {Rationale and Objectives
The current clinical standard for functional imaging of patients with lung ailments is nuclear medicine scintigraphy and Single Photon Emission Computed Tomography ({SPECT}) which detect the gamma decay of inhaled radioactive tracers. Hyperpolarized ({HP}) Xenon-129 {MRI} ({XeMRI}) of the lungs has recently been {FDA} approved and provides similar functional images of the lungs with higher spatial resolution than scintigraphy and {SPECT}. Here we compare Technetium-99m (99mTc) diethylene-triamine-pentaacetate scintigraphy and {SPECT} with {HP} {XeMRI} in healthy controls, asthma, and chronic obstructive pulmonary disorder ({COPD}) patients.
Materials and Methods
59 subjects, healthy, with asthma, and with {COPD}, underwent 99mTc scintigraphy/{SPECT}, standard spirometry, and {HP} {XeMRI}. {XeMRI} and {SPECT} images were registered for direct voxel-wise signal comparisons. Images were also compared using ventilation defect percentage ({VDP}), and a standard 6-compartment method. {VDP} calculated from {XeMRI} and {SPECT} images was compared to spirometry.
Results
Median Pearson correlation coefficient for voxel-wise signal comparison was 0.698 (0.613–0.782) between scintigraphy and {XeMRI} and 0.398 (0.286–0.502) between {SPECT} and {XeMRI}. Correlation between {VDP} measures was r = 0.853, p {\textless} 0.05. {VDP} separated asthma and {COPD} from the control group and was significantly correlated with {FEV}1, {FEV}1/{FVC}, and {FEF} 25–75.
Conclusion
{HP} {XeMRI} provides equivalent information to 99mTc {SPECT} and standard spirometry measures. Additionally, {XeMRI} is non-invasive, hence it could be used for longitudinal studies for evaluating emerging treatment for lung ailments.},
	pages = {1666--1675},
	number = {4},
	journaltitle = {Academic Radiology},
	shortjournal = {Academic Radiology},
	author = {Peiffer, J. D. and Altes, Talissa and Ruset, Iulian C. and Hersman, F. W. and Mugler, John P. and Meyer, Craig H. and Mata, Jamie and Qing, Kun and Thomen, Robert},
	urldate = {2024-06-07},
	date = {2024-04-01},
	keywords = {{MRI}, Hyperpolarized, Lungs, {SPECT}, Xenon},
}

@misc{cotton_markerless_2023,
	title = {Markerless Motion Capture and Biomechanical Analysis Pipeline},
	url = {http://arxiv.org/abs/2303.10654},
	abstract = {Markerless motion capture using computer vision and human pose estimation ({HPE}) has the potential to expand access to precise movement analysis. This could greatly beneﬁt rehabilitation by enabling more accurate tracking of outcomes and providing more sensitive tools for research. There are numerous steps between obtaining videos to extracting accurate biomechanical results and limited research to guide many critical design decisions in these pipelines. In this work, we analyze several of these steps including the algorithm used to detect keypoints and the keypoint set, the approach to reconstructing trajectories for biomechanical inverse kinematics and optimizing the {IK} process. Several features we ﬁnd important are: 1) using a recent algorithm trained on many datasets that produces a dense set of biomechanically-motivated keypoints, 2) using an implicit representation to reconstruct smooth, anatomically constrained marker trajectories for {IK}, 3) iteratively optimizing the biomechanical model to match the dense markers, 4) appropriate regularization of the {IK} process. Our pipeline makes it easy to obtain accurate biomechanical estimates of movement in a rehabilitation hospital.},
	number = {{arXiv}:2303.10654},
	publisher = {{arXiv}},
	author = {Cotton, R. James and {DeLillo}, Allison and Cimorelli, Anthony and Shah, Kunal and Peiffer, J. D. and Anarwala, Shawana and Abdou, Kayan and Karakostas, Tasos},
	urldate = {2024-06-19},
	date = {2023-03-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2303.10654 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{cotton_self-supervised_2023,
	location = {Cham},
	title = {Self-Supervised Learning of Gait-Based Biomarkers},
	isbn = {978-3-031-46005-0},
	doi = {10.1007/978-3-031-46005-0_24},
	abstract = {Markerless motion capture ({MMC}) is revolutionizing gait analysis in clinical settings by making it more accessible, raising the question of how to extract the most clinically meaningful information from gait data. In multiple fields ranging from image processing to natural language processing, self-supervised learning ({SSL}) from large amounts of unannotated data produces very effective representations for downstream tasks. However, there has only been limited use of {SSL} to learn effective representations of gait and movement, and it has not been applied to gait analysis with {MMC}. One {SSL} objective that has not been applied to gait is contrastive learning, which finds representations that place similar samples closer together in the learned space. If the learned similarity metric captures clinically meaningful differences, this could produce a useful representation for many downstream clinical tasks. Contrastive learning can also be combined with causal masking to predict future timesteps, which is an appealing {SSL} objective given the dynamical nature of gait. We applied these techniques to gait analyses performed with {MMC} in a rehabilitation hospital from a diverse clinical population. We find that contrastive learning on unannotated gait data learns a representation that captures clinically meaningful information. We probe this learned representation using the framework of biomarkers and show it holds promise as both a diagnostic and response biomarker, by showing it can accurately classify diagnosis from gait and is responsive to inpatient therapy, respectively. We ultimately hope these learned representations will enable predictive and prognostic gait-based biomarkers that can facilitate precision rehabilitation through greater use of {MMC} to quantify movement in rehabilitation.},
	pages = {277--291},
	booktitle = {Predictive Intelligence in Medicine},
	publisher = {Springer Nature Switzerland},
	author = {Cotton, R. James and Peiffer, J. D. and Shah, Kunal and {DeLillo}, Allison and Cimorelli, Anthony and Anarwala, Shawana and Abdou, Kayan and Karakostas, Tasos},
	editor = {Rekik, Islem and Adeli, Ehsan and Park, Sang Hyun and Cintas, Celia and Zamzmi, Ghada},
	date = {2023},
	langid = {english},
	keywords = {gait analysis, rehabilitation, contrastive learning, gait biomarkers, markerless motion capture, self-supervised learning},
}

@inproceedings{peiffer_fusing_2024-1,
	title = {Fusing Uncalibrated {IMUs} and Handheld Smartphone Video to Reconstruct Knee Kinematics},
	url = {https://ieeexplore.ieee.org/document/10719724},
	doi = {10.1109/BioRob60516.2024.10719724},
	abstract = {Video and wearable sensor data provide comple-mentary information about human movement. Video provides a holistic understanding of the entire body in the world while wearable sensors, namely inertial measurement units ({IMUs}), provide high-resolution measurements of specific body segments. A robust method to fuse these modalities and obtain biomechanically accurate kinematics would have substantial utility for clinical assessment and monitoring. Although multiple video-sensor fusion methods exist, most assume that a time-intensive and often brittle sensor-body calibration process has already been completed. In this work, we employ an implicit function to combine handheld smartphone video and uncalibrated {IMU} data at their full temporal resolution. Our monocular, video-only, biomechanical reconstruction already performs well, with only 3.91 (1.55) degrees of mean adjusted angular error in knee kinematics across 60 recordings. Re-constructing from a fusion of video and {IMU} data reduces this error to 2.9 (1.27) degrees. We validate this method in a diverse group including individuals with no gait impairments, lower limb prosthesis users, and those with a history of stroke. We also show that {IMU} data allows accurate tracking through periods of visual occlusion, equivalent to video-only.},
	eventtitle = {2024 10th {IEEE} {RAS}/{EMBS} International Conference for Biomedical Robotics and Biomechatronics ({BioRob})},
	pages = {1275--1282},
	booktitle = {2024 10th {IEEE} {RAS}/{EMBS} International Conference for Biomedical Robotics and Biomechatronics ({BioRob})},
	author = {Peiffer, J.D. and Shah, Kunal and Anarwala, Shawana and Abdou, Kayan and Cotton, R. James},
	urldate = {2024-10-25},
	date = {2024-09},
	note = {{ISSN}: 2155-1782},
	keywords = {Biomechanics, Kinematics, Accuracy, Calibration, Fuses, Knee, Robot sensing systems, Three-dimensional displays, Visualization, Wearable sensors},
}

@misc{unger_differentiable_2024,
	title = {Differentiable Biomechanics for Markerless Motion Capture in Upper Limb Stroke Rehabilitation: A Comparison with Optical Motion Capture},
	url = {http://arxiv.org/abs/2411.14992},
	doi = {10.48550/arXiv.2411.14992},
	shorttitle = {Differentiable Biomechanics for Markerless Motion Capture in Upper Limb Stroke Rehabilitation},
	abstract = {Marker-based Optical Motion Capture ({OMC}) paired with biomechanical modeling is currently considered the most precise and accurate method for measuring human movement kinematics. However, combining differentiable biomechanical modeling with Markerless Motion Capture ({MMC}) offers a promising approach to motion capture in clinical settings, requiring only minimal equipment, such as synchronized webcams, and minimal effort for data collection. This study compares key kinematic outcomes from biomechanically modeled {MMC} and {OMC} data in 15 stroke patients performing the drinking task, a functional task recommended for assessing upper limb movement quality. We observed a high level of agreement in kinematic trajectories between {MMC} and {OMC}, as indicated by high correlations (median r above 0.95 for the majority of kinematic trajectories) and median {RMSE} values ranging from 2-5 degrees for joint angles, 0.04 m/s for end-effector velocity, and 6 mm for trunk displacement. Trial-to-trial biases between {OMC} and {MMC} were consistent within participant sessions, with interquartile ranges of bias around 1-3 degrees for joint angles, 0.01 m/s in end-effector velocity, and approximately 3mm for trunk displacement. Our findings indicate that our {MMC} for arm tracking is approaching the accuracy of marker-based methods, supporting its potential for use in clinical settings. {MMC} could provide valuable insights into movement rehabilitation in stroke patients, potentially enhancing the effectiveness of rehabilitation strategies.},
	number = {{arXiv}:2411.14992},
	publisher = {{arXiv}},
	author = {Unger, Tim and Moslehian, Arash Sal and Peiffer, J. D. and Ullrich, Johann and Gassert, Roger and Lambercy, Olivier and Cotton, R. James and Easthope, Chris Awai},
	urldate = {2024-11-25},
	date = {2024-11-22},
	eprinttype = {arxiv},
	eprint = {2411.14992},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{firouzabadi_biomechanical_2024,
	title = {Biomechanical Arm and Hand Tracking with Multiview Markerless Motion Capture},
	url = {https://ieeexplore.ieee.org/document/10719940/?arnumber=10719940},
	doi = {10.1109/BioRob60516.2024.10719940},
	abstract = {Human arm and hand function is extremely complex with many degrees of freedom. It is also a common target for clinical interventions. However, precisely measuring upper extremity movement in both clinical and research settings is logistically challenging. We overcame this challenge through a novel approach to reconstructing arm biomechanics from markerless motion capture from multiple synchronized videos. Our approach directly opti-mizes the kinematics of an accurate biomechanical arm and hand that allows end-to-end minimization of the errors between the reconstructed movements and keypoints detected by computer vision. Key to this is an implicit function that maps from time to joint kinematics, which provides a learnable trajectory representation that can be differentiated through the biomechanical model, and supports {GPU} acceleration using {MuJoCo}-{MJX}. This optimization solves for the inverse kinematic solution consistent with the measured keypoints, consistent with biomechanical constraints, in addition to scaling the model while solving for the kinematics. We compare different hand keypoint detectors and find the best produces a fit with only several millimeters of reconstruction error. We also find that end-to-end optimization outperforms a two-stage fitting procedure, equivalent to more traditional biomechanical pipelines, where we first compute 3D marker trajectories and then perform inverse kinematics fitting in {OpenSim}. We anticipate this framework will reduce the barriers to biomechanical analysis of the arm and hand in both clinical and research settings.},
	eventtitle = {2024 10th {IEEE} {RAS}/{EMBS} International Conference for Biomedical Robotics and Biomechatronics ({BioRob})},
	pages = {1641--1648},
	booktitle = {2024 10th {IEEE} {RAS}/{EMBS} International Conference for Biomedical Robotics and Biomechatronics ({BioRob})},
	author = {Firouzabadi, Pouyan and Murray, Wendy and Sobinov, Anton R and Peiffer, J.D. and Shah, Kunal and Miller, Lee E and Cotton, R. James},
	urldate = {2024-11-28},
	date = {2024-09},
	note = {{ISSN}: 2155-1782},
	keywords = {Biomechanics, Motion capture, Computational modeling, Optimization, Biological system modeling, Fitting, Graphics processing units, Tracking, Trajectory, Videos},
}
